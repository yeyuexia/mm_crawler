需求如下：
Python写个爬虫把22mm.cc上的美女图片爬下来，我们把这个爬虫项目命名为：mm_crawler。

需满足：
1. 不要把非相关的图片也爬了；
2. 你总该考虑多线程吧？或者协程；
3. 命令行-h可以查看程序运行帮助，-n可以指定并发线程数（默认10个），-o可以指定图片存储在哪个目录（默认当前运行目录的pics目录下），-l可以限制爬多少图片就结束（默认不限制）；
4. 思考个问题，如果下次我要爬其他的美女网站，你这个程序如何尽可能利于复用；
5. 把你的实现思路清晰记录在该爬虫项目的目录下：readme.txt；
6. 你可以用Python内置模块与第三方模块来加速你这个任务；
7. 两周内搞定；


基于以上需求，
该项目使用多线程的类Worker执行爬取网页并分析，下载图片的功能。并使用一个Master类进行线程的统一管理。Worker需要从Master里取得所要爬取的url和url类型，而当爬取网页的时候，则将网页中的url再上传给Master。
其中Master需要满足以下功能：
1.能够存储需要爬取的url，并且必须保证线程同步。
2.能够检查url是否已经被爬取过或者将要被爬取。
其中Worker需要满足以下功能：
1.能够从Master去得要爬取的url
2.能够爬取url
3.能够分析抓去的网页信息，提取出所需要继续爬取的url和图片地址。
4.能够下载并储存图片。
5.能够将分析取得的url推送给Master。
6.当发现下载的图片数量已经足够时，停止任务。
7.能够应付程序内部错误并重启恢复。

基于以上几点，
1.Master使用Queue来存储url。
2.为了简便，暂时使用set()来存储已经和将要爬取的url(需要更换为数据库来存储，不然当抓取url数量太大会导致内存溢出）
3.简单分析目标网站，发现对方图片存储格式较为单一，所以为了方便暂时使用简单的方法进行抓取和过滤，后期优化可以考虑用更复杂的算法提高准确率
4.暂时把分析html的代码放在worker里面，后期优化的时候可以将这块内容提出单独写一个类。
